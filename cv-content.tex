% ===============================================
% USER CONTENT FILE
% Edit this file to add your personal information
% ===============================================

% ===============================================
% PERSONAL INFORMATION
% ===============================================

\name{Fabio J.}{Fehr, PhD}
\title{Postdoctoral Researcher in Machine learning,\newline University of Oxford}
\email{fabiojfehr@robots.ox.ac.uk}
\homepage{fjfehr.github.io}
\social[linkedin]{fabio-j-fehr}
\extrainfo{\faGraduationCap~\href{https://scholar.google.com/citations?user=WaZWY0wAAAAJ}{Google Scholar}}

% ===============================================
% RESEARCH SUMMARY (2 lines)
% ===============================================

\newcommand{\userbio}{%
Research scientist specialising in representation learning and generalisation for large language models. Current work: legal reasoning, agentic systems and trustworthy AI.
}

% ===============================================
% RESEARCH INTERESTS & CORE EXPERTISE
% ===============================================

\newcommand{\userinterests}{%
\textbf{Representation Learning} $\cdot$ \textbf{Natural Language Processing (NLP)} $\cdot$ \textbf{Generalisation \& Robustness} $\cdot$ \textbf{Large Language Models (LLMs)} $\cdot$  \textbf{Foundation Models} $\cdot$ \textbf{Agentic Systems} $\cdot$ \textbf{Out-of-Distribution (OOD) Evaluation} $\cdot$ \textbf{Model Fine-tuning} $\cdot$ \textbf{Distributed Training} $\cdot$ \textbf{Retrieval Augmented Generation (RAG)} $\cdot$ \textbf{Information Theory}
}

% ===============================================
% RESEARCH EXPERIENCE
% ===============================================

\newcommand{\userexperience}{%
  
\cventry{2026--Present}{Postdoctoral Researcher}{University of Oxford}{UK}{Advisor: Prof. Philip Torr}{Leading research on agentic language models for legal reasoning. Interdisciplinary collaboration.}

\cventry{2021--2025}{PhD Researcher}{EPFL \& Idiap}{Switzerland}{Advisor: Dr. James Henderson}{Proposed and developed NVIB framework for Transformers; designed end-to-end training and evaluation pipelines. Led collaborative team of 8 PhDs and 3 PIs on fine-tuning project. Published 6 papers (4 first/lead-author); improved OOD generalisation across text, graphs, speech, and vision. Open-sourced reproducible code.}

\cventry{2024}{Applied Data Scientist (Intern)}{Amazon}{Germany}{}{Improved retriever in RAG pipeline for code generation; designed lightweight model integrating code semantics and embeddings. First author on ACL 2025 paper.}

\cventry{2018}{Machine Learning Engineer (Intern)}{DataProphet}{South Africa}{}{Applied transfer learning with RNN/CNN models to financial time series; deployed on Google Cloud.}

\cventry{2017-2018}{Data Scientist (Intern)}{Eighty20}{South Africa}{}{Data analysis and visualisation for social impact projects using R and SQL.}

}

% ===============================================
% EDUCATION
% ===============================================

\newcommand{\usereducation}{%
  
\cventry{2021--2025}{PhD in Machine Learning}{EPFL \& Idiap}{Switzerland}{Advisor: Dr. James Henderson}{Thesis: \textit{Nonparametric Variational Information Bottleneck: Attention-based Architectures as Latent Variable Models}. Representation learning, NLP, Bayesian nonparametrics.}

\cventry{2019--2020}{MSc in Statistics}{University of Cape Town}{South Africa}{}{Bayesian statistics, machine learning, biomedical modelling, deep learning.}

\cventry{2015--2018}{Bachelor of Business Science (Statistics)}{University of Cape Town}{South Africa}{}{Statistics, Mathematics, Computer Science, Economics.}

}

% ===============================================
% TECHNICAL SKILLS
% ===============================================

\newcommand{\userskills}{%
\cvitem{Languages}{Python, CUDA, C++, Java, R, Scala}
\cvitem{Frameworks}{PyTorch, TensorFlow, JAX, Triton, HuggingFace Transformers}
\cvitem{Systems \& Tools}{Docker, Google Cloud, Weights \& Biases, Git, LaTeX}
}

% ===============================================
% SELECTED PUBLICATIONS (6 papers, top venues)
% ===============================================

\newcommand{\userpublications}{%
\cvitem{}{\textbf{6 publications} in top-tier venues including ICLR, ACL, COLM and EMNLP. \textbf{4 first/lead-author} contributions.}
\vspace{0.3em}

\cvitem{2025}{\textbf{Fehr, F. J.}, Sivaprasad, P. T., Franceschi, L., Zappella, G. \textit{CoRet: Improved Retriever for Code Editing.} ACL 2025.}

\cvitem{2025}{\textbf{Fehr, F. J.}, Baia, A. E., Chang, X., Coman, A. C., El Hajal, K., El Zein, D., Kumar, S., Zuluaga Gomez, J. P., Cavallaro, A., Teney, D., Henderson, J. \textit{Fine-Tuning Pretrained Models with NVIB for Improved Generalisation.} ICLR Workshop SCSL 2025.}

\cvitem{2024}{\textbf{Fehr, F.}, Henderson, J. \textit{Nonparametric Variational Regularisation of Pretrained Transformers.} COLM 2024.}

\cvitem{2023}{Behjati, M.*, \textbf{Fehr, F.}*, Henderson, J. \textit{Learning to Abstract with Nonparametric Variational Information Bottleneck.} EMNLP Findings 2023.}

\cvitem{2023}{Henderson, J., \textbf{Fehr, F. J.} \textit{A VAE for Transformers with Nonparametric Variational Information Bottleneck.} ICLR 2023.}

\cvitem{2023}{Mai, F., Pannatier, A., \textbf{Fehr, F.}, Chen, H., Marelli, F., Fleuret, F., Henderson, J. \textit{HyperMixer: An MLP-based Low Cost Alternative to Transformers.} ACL 2023.}
}

% ===============================================
% AWARDS & LEADERSHIP
% ===============================================

\newcommand{\userawards}{%
\cvitem{2025}{\textbf{PhD Student Award of the Year} -- Idiap Research Institute (research excellence and community contribution)}
\cvitem{2025}{\textbf{Idiap Create Challenge -- 1st Place} (15,000 CHF) -- SYNTH\textit{IA}: Real-time AI musician with our generative AI music model}
\cvitem{2019}{\textbf{UCT Surf Club Chairman} -- Sports Club of the Year \& Societal Impact Award}
\cvitem{2018}{\textbf{Entrepreneurial Project Finalist} -- Mazars Consultancy (Top 6 of 84 teams)}
}

% ===============================================
% TEACHING & MENTORING (compressed)
% ===============================================

\newcommand{\userteaching}{%
\cvitem{2017--2024}{\textbf{Teaching \& Mentoring across 4 institutions:} EPFL (Deep Learning, NLP, supervised 2 projects at PhD level), UCT (Statistics Course Coordinator for 1000+ students, managed 20 tutors), GetSmarter/LSE (Machine Learning teaching and course creation), UniDistance Suisse (AI Master's program).}
}

% ===============================================
% ADDITIONAL INFORMATION
% ===============================================

\newcommand{\useradditional}{%
\cvitem{Languages}{English (native), French, German, Afrikaans}
\cvitem{Professional Skills}{Scientific writing, cross-functional collaboration, research mentorship, public speaking}
}
